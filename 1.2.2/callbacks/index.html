<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Callbacks - Keras Documentation</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Callbacks";
    var mkdocs_page_input_path = "callbacks.md";
    var mkdocs_page_url = "/callbacks/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-61785484-1', 'keras.io');
      ga('send', 'pageview');
  </script>
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Keras Documentation</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Getting started</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../getting-started/sequential-model-guide/">Guide to the Sequential model</a>
                </li>
                <li class="">
                    
    <a class="" href="../getting-started/functional-api-guide/">Guide to the Functional API</a>
                </li>
                <li class="">
                    
    <a class="" href="../getting-started/faq/">FAQ</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Models</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../models/about-keras-models/">About Keras models</a>
                </li>
                <li class="">
                    
    <a class="" href="../models/sequential/">Sequential</a>
                </li>
                <li class="">
                    
    <a class="" href="../models/model/">Model (functional API)</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Layers</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../layers/about-keras-layers/">About Keras layers</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/core/">Core Layers</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/convolutional/">Convolutional Layers</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/pooling/">Pooling Layers</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/local/">Locally-connected Layers</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/recurrent/">Recurrent Layers</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/embeddings/">Embedding Layers</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/advanced-activations/">Advanced Activations Layers</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/normalization/">Normalization Layers</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/noise/">Noise layers</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/wrappers/">Layer wrappers</a>
                </li>
                <li class="">
                    
    <a class="" href="../layers/writing-your-own-keras-layers/">Writing your own Keras layers</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Preprocessing</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../preprocessing/sequence/">Sequence Preprocessing</a>
                </li>
                <li class="">
                    
    <a class="" href="../preprocessing/text/">Text Preprocessing</a>
                </li>
                <li class="">
                    
    <a class="" href="../preprocessing/image/">Image Preprocessing</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../objectives/">Objectives</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../metrics/">Metrics</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../optimizers/">Optimizers</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../activations/">Activations</a>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">Callbacks</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#usage-of-callbacks">Usage of callbacks</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#callback">Callback</a></li>
        
            <li><a class="toctree-l3" href="#baselogger">BaseLogger</a></li>
        
            <li><a class="toctree-l3" href="#progbarlogger">ProgbarLogger</a></li>
        
            <li><a class="toctree-l3" href="#history">History</a></li>
        
            <li><a class="toctree-l3" href="#modelcheckpoint">ModelCheckpoint</a></li>
        
            <li><a class="toctree-l3" href="#earlystopping">EarlyStopping</a></li>
        
            <li><a class="toctree-l3" href="#remotemonitor">RemoteMonitor</a></li>
        
            <li><a class="toctree-l3" href="#learningratescheduler">LearningRateScheduler</a></li>
        
            <li><a class="toctree-l3" href="#tensorboard">TensorBoard</a></li>
        
            <li><a class="toctree-l3" href="#reducelronplateau">ReduceLROnPlateau</a></li>
        
            <li><a class="toctree-l3" href="#csvlogger">CSVLogger</a></li>
        
            <li><a class="toctree-l3" href="#lambdacallback">LambdaCallback</a></li>
        
        </ul>
    

    <li class="toctree-l2"><a href="#create-a-callback">Create a callback</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#example-recording-loss-history">Example: recording loss history</a></li>
        
            <li><a class="toctree-l3" href="#example-model-checkpoints">Example: model checkpoints</a></li>
        
        </ul>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../datasets/">Datasets</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../applications/">Applications</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../backend/">Backend</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../initializations/">Initializations</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../regularizers/">Regularizers</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../constraints/">Constraints</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../visualization/">Visualization</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../scikit-learn-api/">Scikit-learn API</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Utils</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../utils/data_utils/">Data Utils</a>
                </li>
                <li class="">
                    
    <a class="" href="../utils/io_utils/">I/O Utils</a>
                </li>
                <li class="">
                    
    <a class="" href="../utils/layer_utils/">Layer Utils</a>
                </li>
                <li class="">
                    
    <a class="" href="../utils/np_utils/">Numpy Utils</a>
                </li>
                <li class="">
                    
    <a class="" href="../utils/generic_utils/">Generic Utils</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Keras Documentation</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Callbacks</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="http://github.com/fchollet/keras/edit/master/docs/callbacks.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h2 id="usage-of-callbacks">Usage of callbacks</h2>
<p>A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. You can pass a list of callbacks (as the keyword argument <code>callbacks</code>) to the <code>.fit()</code> method of the <code>Sequential</code> model. The relevant methods of the callbacks will then be called at each stage of the training. </p>
<hr />
<p><span style="float:right;"><a href="https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L142">[source]</a></span></p>
<h3 id="callback">Callback</h3>
<pre><code class="python">keras.callbacks.Callback()
</code></pre>

<p>Abstract base class used to build new callbacks.</p>
<p><strong>Properties</strong></p>
<ul>
<li><strong>params</strong>: dict. Training parameters
    (eg. verbosity, batch size, number of epochs...).</li>
<li><strong>model</strong>: instance of <code>keras.models.Model</code>.
    Reference of the model being trained.</li>
</ul>
<p>The <code>logs</code> dictionary that callback methods
take as argument will contain keys for quantities relevant to
the current batch or epoch.</p>
<p>Currently, the <code>.fit()</code> method of the <code>Sequential</code> model class
will include the following quantities in the <code>logs</code> that
it passes to its callbacks:</p>
<ul>
<li><strong>on_epoch_end</strong>: logs include <code>acc</code> and <code>loss</code>, and
    optionally include <code>val_loss</code>
    (if validation is enabled in <code>fit</code>), and <code>val_acc</code>
    (if validation and accuracy monitoring are enabled).</li>
<li><strong>on_batch_begin</strong>: logs include <code>size</code>,
    the number of samples in the current batch.</li>
<li><strong>on_batch_end</strong>: logs include <code>loss</code>, and optionally <code>acc</code>
    (if accuracy monitoring is enabled).</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L197">[source]</a></span></p>
<h3 id="baselogger">BaseLogger</h3>
<pre><code class="python">keras.callbacks.BaseLogger()
</code></pre>

<p>Callback that accumulates epoch averages of metrics.</p>
<p>This callback is automatically applied to every Keras model.</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L226">[source]</a></span></p>
<h3 id="progbarlogger">ProgbarLogger</h3>
<pre><code class="python">keras.callbacks.ProgbarLogger()
</code></pre>

<p>Callback that prints metrics to stdout.</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L268">[source]</a></span></p>
<h3 id="history">History</h3>
<pre><code class="python">keras.callbacks.History()
</code></pre>

<p>Callback that records events into a <code>History</code> object.</p>
<p>This callback is automatically applied to
every Keras model. The <code>History</code> object
gets returned by the <code>fit</code> method of models.</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L287">[source]</a></span></p>
<h3 id="modelcheckpoint">ModelCheckpoint</h3>
<pre><code class="python">keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)
</code></pre>

<p>Save the model after every epoch.</p>
<p><code>filepath</code> can contain named formatting options,
which will be filled the value of <code>epoch</code> and
keys in <code>logs</code> (passed in <code>on_epoch_end</code>).</p>
<p>For example: if <code>filepath</code> is <code>weights.{epoch:02d}-{val_loss:.2f}.hdf5</code>,
then the model checkpoints will be saved with the epoch number and
the validation loss in the filename.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><strong>filepath</strong>: string, path to save the model file.</li>
<li><strong>monitor</strong>: quantity to monitor.</li>
<li><strong>verbose</strong>: verbosity mode, 0 or 1.</li>
<li><strong>save_best_only</strong>: if <code>save_best_only=True</code>,
    the latest best model according to
    the quantity monitored will not be overwritten.</li>
<li><strong>mode</strong>: one of {auto, min, max}.
    If <code>save_best_only=True</code>, the decision
    to overwrite the current save file is made
    based on either the maximization or the
    minimization of the monitored quantity. For <code>val_acc</code>,
    this should be <code>max</code>, for <code>val_loss</code> this should
    be <code>min</code>, etc. In <code>auto</code> mode, the direction is
    automatically inferred from the name of the monitored quantity.</li>
<li><strong>save_weights_only</strong>: if True, then only the model's weights will be
    saved (<code>model.save_weights(filepath)</code>), else the full model
    is saved (<code>model.save(filepath)</code>).</li>
<li><strong>period</strong>: Interval (number of epochs) between checkpoints.</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L387">[source]</a></span></p>
<h3 id="earlystopping">EarlyStopping</h3>
<pre><code class="python">keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')
</code></pre>

<p>Stop training when a monitored quantity has stopped improving.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><strong>monitor</strong>: quantity to be monitored.</li>
<li><strong>min_delta</strong>: minimum change in the monitored quantity
    to qualify as an improvement, i.e. an absolute
    change of less than min_delta, will count as no
    improvement.</li>
<li><strong>patience</strong>: number of epochs with no improvement
    after which training will be stopped.</li>
<li><strong>verbose</strong>: verbosity mode.</li>
<li><strong>mode</strong>: one of {auto, min, max}. In <code>min</code> mode,
    training will stop when the quantity
    monitored has stopped decreasing; in <code>max</code>
    mode it will stop when the quantity
    monitored has stopped increasing; in <code>auto</code>
    mode, the direction is automatically inferred
    from the name of the monitored quantity.</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L464">[source]</a></span></p>
<h3 id="remotemonitor">RemoteMonitor</h3>
<pre><code class="python">keras.callbacks.RemoteMonitor(root='http://localhost:9000', path='/publish/epoch/end/', field='data', headers=None)
</code></pre>

<p>Callback used to stream events to a server.</p>
<p>Requires the <code>requests</code> library.
Events are sent to <code>root + '/publish/epoch/end/'</code> by default. Calls are
HTTP POST, with a <code>data</code> argument which is a
JSON-encoded dictionary of event data.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><strong>root</strong>: String; root url of the target server.</li>
<li><strong>path</strong>: String; path relative to <code>root</code> to which the events will be sent.</li>
<li><strong>field</strong>: String; JSON field under which the data will be stored.</li>
<li><strong>headers</strong>: Dictionary; optional custom HTTP headers.
    Defaults to:<ul>
<li><strong>`{'Accept'</strong>: 'application/json',</li>
<li><strong>'Content-Type'</strong>: 'application/json'}`</li>
</ul>
</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L514">[source]</a></span></p>
<h3 id="learningratescheduler">LearningRateScheduler</h3>
<pre><code class="python">keras.callbacks.LearningRateScheduler(schedule)
</code></pre>

<p>Learning rate scheduler.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><strong>schedule</strong>: a function that takes an epoch index as input
    (integer, indexed from 0) and returns a new
    learning rate as output (float).</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L537">[source]</a></span></p>
<h3 id="tensorboard">TensorBoard</h3>
<pre><code class="python">keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)
</code></pre>

<p>Tensorboard basic visualizations.</p>
<p>This callback writes a log for TensorBoard, which allows
you to visualize dynamic graphs of your training and test
metrics, as well as activation histograms for the different
layers in your model.</p>
<p>TensorBoard is a visualization tool provided with TensorFlow.</p>
<p>If you have installed TensorFlow with pip, you should be able
to launch TensorBoard from the command line:</p>
<pre><code>tensorboard --logdir=/full_path_to_your_logs
</code></pre>

<p>You can find more information about TensorBoard
- __<a href="../https__://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html">here</a>.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><strong>log_dir</strong>: the path of the directory where to save the log
    files to be parsed by Tensorboard</li>
<li><strong>histogram_freq</strong>: frequency (in epochs) at which to compute activation
    histograms for the layers of the model. If set to 0,
    histograms won't be computed.</li>
<li><strong>write_graph</strong>: whether to visualize the graph in Tensorboard.
    The log file can become quite large when
    write_graph is set to True.</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L671">[source]</a></span></p>
<h3 id="reducelronplateau">ReduceLROnPlateau</h3>
<pre><code class="python">keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)
</code></pre>

<p>Reduce learning rate when a metric has stopped improving.</p>
<p>Models often benefit from reducing the learning rate by a factor
of 2-10 once learning stagnates. This callback monitors a
quantity and if no improvement is seen for a 'patience' number
of epochs, the learning rate is reduced.</p>
<p><strong>Example</strong></p>
<pre><code class="python">    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                  patience=5, min_lr=0.001)
    model.fit(X_train, Y_train, callbacks=[reduce_lr])
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><strong>monitor</strong>: quantity to be monitored.</li>
<li><strong>factor</strong>: factor by which the learning rate will
    be reduced. new_lr = lr * factor</li>
<li><strong>patience</strong>: number of epochs with no improvement
    after which learning rate will be reduced.</li>
<li><strong>verbose</strong>: int. 0: quiet, 1: update messages.</li>
<li><strong>mode</strong>: one of {auto, min, max}. In <code>min</code> mode,
    lr will be reduced when the quantity
    monitored has stopped decreasing; in <code>max</code>
    mode it will be reduced when the quantity
    monitored has stopped increasing; in <code>auto</code>
    mode, the direction is automatically inferred
    from the name of the monitored quantity.</li>
<li><strong>epsilon</strong>: threshold for measuring the new optimum,
    to only focus on significant changes.</li>
<li><strong>cooldown</strong>: number of epochs to wait before resuming
    normal operation after lr has been reduced.</li>
<li><strong>min_lr</strong>: lower bound on the learning rate.</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L782">[source]</a></span></p>
<h3 id="csvlogger">CSVLogger</h3>
<pre><code class="python">keras.callbacks.CSVLogger(filename, separator=',', append=False)
</code></pre>

<p>Callback that streams epoch results to a csv file.</p>
<p>Supports all values that can be represented as a string,
including 1D iterables such as np.ndarray.</p>
<p><strong>Example</strong></p>
<pre><code class="python">    csv_logger = CSVLogger('training.log')
    model.fit(X_train, Y_train, callbacks=[csv_logger])
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><strong>filename</strong>: filename of the csv file, e.g. 'run/log.csv'.</li>
<li><strong>separator</strong>: string used to separate elements in the csv file.</li>
<li><strong>append</strong>: True: append if file exists (useful for continuing
    training). False: overwrite existing file,</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/fchollet/keras/blob/master/keras/callbacks.py#L850">[source]</a></span></p>
<h3 id="lambdacallback">LambdaCallback</h3>
<pre><code class="python">keras.callbacks.LambdaCallback(on_epoch_begin=None, on_epoch_end=None, on_batch_begin=None, on_batch_end=None, on_train_begin=None, on_train_end=None)
</code></pre>

<p>Callback for creating simple, custom callbacks on-the-fly.</p>
<p>This callback is constructed with anonymous functions that will be called
at the appropriate time. Note that the callbacks expects positional
arguments, as:
 - <code>on_epoch_begin</code> and <code>on_epoch_end</code> expect two positional arguments:
<code>epoch</code>, <code>logs</code>
 - <code>on_batch_begin</code> and <code>on_batch_end</code> expect two positional arguments:
<code>batch</code>, <code>logs</code>
 - <code>on_train_begin</code> and <code>on_train_end</code> expect one positional argument:
<code>logs</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><strong>on_epoch_begin</strong>: called at the beginning of every epoch.</li>
<li><strong>on_epoch_end</strong>: called at the end of every epoch.</li>
<li><strong>on_batch_begin</strong>: called at the beginning of every batch.</li>
<li><strong>on_batch_end</strong>: called at the end of every batch.</li>
<li><strong>on_train_begin</strong>: called at the beginning of model training.</li>
<li><strong>on_train_end</strong>: called at the end of model training.</li>
</ul>
<p><strong>Example</strong></p>
<pre><code class="python"># Print the batch number at the beginning of every batch.
batch_print_callback = LambdaCallback(
    on_batch_begin=lambda batch,logs: print(batch))

# Plot the loss after every epoch.
import numpy as np
import matplotlib.pyplot as plt
plot_loss_callback = LambdaCallback(
    on_epoch_end=lambda epoch, logs: plt.plot(np.arange(epoch),
                      logs['loss']))

# Terminate some processes after having finished model training.
processes = ...
cleanup_callback = LambdaCallback(
    on_train_end=lambda logs: [
    p.terminate() for p in processes if p.is_alive()])

model.fit(...,
      callbacks=[batch_print_callback,
         plot_loss_callback,
         cleanup_callback])
</code></pre>

<hr />
<h1 id="create-a-callback">Create a callback</h1>
<p>You can create a custom callback by extending the base class <code>keras.callbacks.Callback</code>. A callback has access to its associated model through the class property <code>self.model</code>.</p>
<p>Here's a simple example saving a list of losses over each batch during training:</p>
<pre><code class="python">class LossHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.losses = []

    def on_batch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))
</code></pre>

<hr />
<h3 id="example-recording-loss-history">Example: recording loss history</h3>
<pre><code class="python">class LossHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.losses = []

    def on_batch_end(self, batch, logs={}):
        self.losses.append(logs.get('loss'))

model = Sequential()
model.add(Dense(10, input_dim=784, init='uniform'))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

history = LossHistory()
model.fit(X_train, Y_train, batch_size=128, nb_epoch=20, verbose=0, callbacks=[history])

print history.losses
# outputs
'''
[0.66047596406559383, 0.3547245744908703, ..., 0.25953155204159617, 0.25901699725311789]
'''
</code></pre>

<hr />
<h3 id="example-model-checkpoints">Example: model checkpoints</h3>
<pre><code class="python">from keras.callbacks import ModelCheckpoint

model = Sequential()
model.add(Dense(10, input_dim=784, init='uniform'))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

'''
saves the model weights after each epoch if the validation loss decreased
'''
checkpointer = ModelCheckpoint(filepath=&quot;/tmp/weights.hdf5&quot;, verbose=1, save_best_only=True)
model.fit(X_train, Y_train, batch_size=128, nb_epoch=20, verbose=0, validation_data=(X_test, Y_test), callbacks=[checkpointer])

</code></pre>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../datasets/" class="btn btn-neutral float-right" title="Datasets">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../activations/" class="btn btn-neutral" title="Activations"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="http://github.com/fchollet/keras" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../activations/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../datasets/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../js/theme.js"></script>

</body>
</html>
